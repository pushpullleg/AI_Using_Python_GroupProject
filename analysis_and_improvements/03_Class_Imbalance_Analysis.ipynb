{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03. Class Imbalance Analysis and Solutions\n",
        "\n",
        "## Objective\n",
        "Analyze class imbalance issues, especially for the \"Improving\" class, and implement solutions to improve model performance on minority classes.\n",
        "\n",
        "## Key Questions\n",
        "1. What is the class distribution?\n",
        "2. How does class imbalance affect model performance?\n",
        "3. What techniques can improve performance on minority classes?\n",
        "4. Which approach works best for this problem?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"âœ… Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data and Analyze Class Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('../today/trajectory_ml_ready_advanced.csv')\n",
        "\n",
        "# Prepare features and target\n",
        "drop_cols = ['UNITID', 'Institution_Name', 'Year', 'Target_Trajectory', 'Target_Label', 'State']\n",
        "X = df.drop(columns=drop_cols)\n",
        "y = df['Target_Label'].astype(int)\n",
        "\n",
        "# One-hot encode Division\n",
        "X = pd.get_dummies(X, columns=['Division'], drop_first=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Analyze class distribution\n",
        "print(\"=\" * 60)\n",
        "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "class_names = {0: 'Declining', 1: 'Stable', 2: 'Improving'}\n",
        "\n",
        "print(\"\\nTraining Set:\")\n",
        "train_dist = y_train.value_counts().sort_index()\n",
        "for label, count in train_dist.items():\n",
        "    pct = count / len(y_train) * 100\n",
        "    print(f\"  {class_names[label]}: {count:5d} ({pct:5.2f}%)\")\n",
        "\n",
        "print(\"\\nTest Set:\")\n",
        "test_dist = y_test.value_counts().sort_index()\n",
        "for label, count in test_dist.items():\n",
        "    pct = count / len(y_test) * 100\n",
        "    print(f\"  {class_names[label]}: {count:5d} ({pct:5.2f}%)\")\n",
        "\n",
        "# Calculate imbalance ratio\n",
        "max_class_count = train_dist.max()\n",
        "min_class_count = train_dist.min()\n",
        "imbalance_ratio = max_class_count / min_class_count\n",
        "\n",
        "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
        "print(f\"(Most common class is {imbalance_ratio:.1f}x larger than least common)\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Training set\n",
        "train_dist.plot(kind='bar', ax=axes[0], color=['#e74c3c', '#3498db', '#2ecc71'])\n",
        "axes[0].set_title('Training Set Class Distribution')\n",
        "axes[0].set_xlabel('Class')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_xticklabels([class_names[i] for i in train_dist.index], rotation=0)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Test set\n",
        "test_dist.plot(kind='bar', ax=axes[1], color=['#e74c3c', '#3498db', '#2ecc71'])\n",
        "axes[1].set_title('Test Set Class Distribution')\n",
        "axes[1].set_xlabel('Class')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].set_xticklabels([class_names[i] for i in test_dist.index], rotation=0)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ“Š Chart saved as 'class_distribution.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Baseline Model Performance (Without Balancing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost without any balancing\n",
        "xgb_baseline = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_baseline.fit(X_train, y_train)\n",
        "y_pred_baseline = xgb_baseline.predict(X_test)\n",
        "y_prob_baseline = xgb_baseline.predict_proba(X_test)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"BASELINE MODEL (No Balancing)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob_baseline, multi_class='ovr'):.4f}\")\n",
        "\n",
        "print(\"\\nPer-Class Performance:\")\n",
        "print(classification_report(y_test, y_pred_baseline, \n",
        "                          target_names=['Declining', 'Stable', 'Improving']))\n",
        "\n",
        "# Confusion matrix\n",
        "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Declining', 'Stable', 'Improving'],\n",
        "            yticklabels=['Declining', 'Stable', 'Improving'])\n",
        "plt.title('Confusion Matrix - Baseline (No Balancing)')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_baseline.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Different Balancing Techniques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define balancing techniques to test\n",
        "balancing_techniques = {\n",
        "    'SMOTE': SMOTE(random_state=42),\n",
        "    'ADASYN': ADASYN(random_state=42),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42),\n",
        "    'SMOTETomek': SMOTETomek(random_state=42),\n",
        "    'Class Weights (XGBoost)': None  # Will use scale_pos_weight parameter\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, sampler in balancing_techniques.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Testing: {name}\")\n",
        "    print('='*60)\n",
        "    \n",
        "    if name == 'Class Weights (XGBoost)':\n",
        "        # Use class weights instead of sampling\n",
        "        from sklearn.utils.class_weight import compute_sample_weight\n",
        "        sample_weights = compute_sample_weight('balanced', y_train)\n",
        "        \n",
        "        xgb_weighted = XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=3,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42,\n",
        "            eval_metric='mlogloss'\n",
        "        )\n",
        "        xgb_weighted.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "        y_pred = xgb_weighted.predict(X_test)\n",
        "        y_prob = xgb_weighted.predict_proba(X_test)\n",
        "    else:\n",
        "        # Use sampling technique\n",
        "        pipeline = ImbPipeline([\n",
        "            ('sampler', sampler),\n",
        "            ('classifier', XGBClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=3,\n",
        "                learning_rate=0.1,\n",
        "                random_state=42,\n",
        "                eval_metric='mlogloss'\n",
        "            ))\n",
        "        ])\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "        y_prob = pipeline.predict_proba(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "    \n",
        "    # Per-class metrics\n",
        "    report = classification_report(y_test, y_pred, \n",
        "                                 target_names=['Declining', 'Stable', 'Improving'],\n",
        "                                 output_dict=True)\n",
        "    \n",
        "    results.append({\n",
        "        'Technique': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Declining_F1': report['Declining']['f1-score'],\n",
        "        'Stable_F1': report['Stable']['f1-score'],\n",
        "        'Improving_F1': report['Improving']['f1-score'],\n",
        "        'Macro_F1': report['macro avg']['f1-score']\n",
        "    })\n",
        "    \n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(f\"Macro F1: {report['macro avg']['f1-score']:.4f}\")\n",
        "    print(f\"Improving F1: {report['Improving']['f1-score']:.4f}\")\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON OF BALANCING TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add baseline to comparison\n",
        "baseline_result = {\n",
        "    'Technique': 'No Balancing (Baseline)',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_baseline),\n",
        "    'ROC-AUC': roc_auc_score(y_test, y_prob_baseline, multi_class='ovr'),\n",
        "    'Declining_F1': classification_report(y_test, y_pred_baseline, output_dict=True)['0']['f1-score'],\n",
        "    'Stable_F1': classification_report(y_test, y_pred_baseline, output_dict=True)['1']['f1-score'],\n",
        "    'Improving_F1': classification_report(y_test, y_pred_baseline, output_dict=True)['2']['f1-score'],\n",
        "    'Macro_F1': classification_report(y_test, y_pred_baseline, output_dict=True)['macro avg']['f1-score']\n",
        "}\n",
        "\n",
        "results_df = pd.concat([pd.DataFrame([baseline_result]), results_df], ignore_index=True)\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Accuracy\n",
        "axes[0, 0].barh(results_df['Technique'], results_df['Accuracy'], color='#3498db')\n",
        "axes[0, 0].set_xlabel('Accuracy')\n",
        "axes[0, 0].set_title('Accuracy Comparison')\n",
        "axes[0, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# ROC-AUC\n",
        "axes[0, 1].barh(results_df['Technique'], results_df['ROC-AUC'], color='#2ecc71')\n",
        "axes[0, 1].set_xlabel('ROC-AUC')\n",
        "axes[0, 1].set_title('ROC-AUC Comparison')\n",
        "axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Macro F1\n",
        "axes[1, 0].barh(results_df['Technique'], results_df['Macro_F1'], color='#e74c3c')\n",
        "axes[1, 0].set_xlabel('Macro F1-Score')\n",
        "axes[1, 0].set_title('Macro F1-Score Comparison')\n",
        "axes[1, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Per-class F1\n",
        "x = np.arange(len(results_df))\n",
        "width = 0.25\n",
        "axes[1, 1].bar(x - width, results_df['Declining_F1'], width, label='Declining', color='#e74c3c')\n",
        "axes[1, 1].bar(x, results_df['Stable_F1'], width, label='Stable', color='#3498db')\n",
        "axes[1, 1].bar(x + width, results_df['Improving_F1'], width, label='Improving', color='#2ecc71')\n",
        "axes[1, 1].set_xlabel('Technique')\n",
        "axes[1, 1].set_ylabel('F1-Score')\n",
        "axes[1, 1].set_title('Per-Class F1-Score')\n",
        "axes[1, 1].set_xticks(x)\n",
        "axes[1, 1].set_xticklabels(results_df['Technique'], rotation=45, ha='right')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('balancing_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ“Š Chart saved as 'balancing_comparison.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find best technique\n",
        "best_idx = results_df['Macro_F1'].idxmax()\n",
        "best_technique = results_df.iloc[best_idx]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"RECOMMENDATIONS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nâœ… Best Overall Technique: {best_technique['Technique']}\")\n",
        "print(f\"   Macro F1: {best_technique['Macro_F1']:.4f}\")\n",
        "print(f\"   Accuracy: {best_technique['Accuracy']:.4f}\")\n",
        "print(f\"   ROC-AUC: {best_technique['ROC-AUC']:.4f}\")\n",
        "\n",
        "# Find best for Improving class\n",
        "best_improving_idx = results_df['Improving_F1'].idxmax()\n",
        "best_improving = results_df.iloc[best_improving_idx]\n",
        "\n",
        "print(f\"\\nâœ… Best for 'Improving' Class: {best_improving['Technique']}\")\n",
        "print(f\"   Improving F1: {best_improving['Improving_F1']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nKey Findings:\")\n",
        "print(f\"1. Class imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
        "print(f\"2. 'Improving' class is the minority ({train_dist.min()} samples)\")\n",
        "print(f\"3. Baseline model struggles with 'Improving' class\")\n",
        "print(f\"4. Best balancing technique improves macro F1 by {best_technique['Macro_F1'] - baseline_result['Macro_F1']:.4f}\")\n",
        "\n",
        "print(\"\\nNext Steps:\")\n",
        "print(\"- Use the best technique in final model training\")\n",
        "print(\"- Consider ensemble methods combining multiple techniques\")\n",
        "print(\"- Try cost-sensitive learning with custom class weights\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
