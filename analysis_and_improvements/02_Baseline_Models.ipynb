{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02. Baseline Models Implementation\n",
        "\n",
        "## Objective\n",
        "Implement baseline models to establish a performance floor and demonstrate that ML models add value over simple heuristics.\n",
        "\n",
        "## Baseline Strategies\n",
        "1. **Random Guess**: 33.3% accuracy (3 classes)\n",
        "2. **Majority Class**: Predict most common class\n",
        "3. **Persistence Model**: Predict that future trajectory = current trajectory\n",
        "4. **Simple Rule-Based**: Use simple thresholds on key features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"‚úÖ Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('../today/trajectory_ml_ready_advanced.csv')\n",
        "\n",
        "# Prepare features and target\n",
        "drop_cols = ['UNITID', 'Institution_Name', 'Year', 'Target_Trajectory', 'Target_Label', 'State']\n",
        "X = df.drop(columns=drop_cols)\n",
        "y = df['Target_Label'].astype(int)\n",
        "\n",
        "# One-hot encode Division\n",
        "X = pd.get_dummies(X, columns=['Division'], drop_first=True)\n",
        "\n",
        "# Split data (using same random state as original model for comparison)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training Set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test Set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\nClass Distribution (Train):\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "print(f\"\\nClass Distribution (Test):\")\n",
        "print(y_test.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Baseline 1: Random Guess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random guess: predict each class with equal probability\n",
        "np.random.seed(42)\n",
        "y_pred_random = np.random.choice([0, 1, 2], size=len(y_test))\n",
        "\n",
        "accuracy_random = accuracy_score(y_test, y_pred_random)\n",
        "print(f\"Random Guess Accuracy: {accuracy_random:.4f} ({accuracy_random*100:.2f}%)\")\n",
        "print(f\"Expected: ~33.33% for 3 classes\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_random, \n",
        "                          target_names=['Declining', 'Stable', 'Improving']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Baseline 2: Majority Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict the most common class in training data\n",
        "majority_class = y_train.mode()[0]\n",
        "y_pred_majority = np.full(len(y_test), majority_class)\n",
        "\n",
        "accuracy_majority = accuracy_score(y_test, y_pred_majority)\n",
        "print(f\"Majority Class: {majority_class} ({'Declining' if majority_class == 0 else 'Stable' if majority_class == 1 else 'Improving'})\")\n",
        "print(f\"Majority Class Accuracy: {accuracy_majority:.4f} ({accuracy_majority*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_majority, \n",
        "                          target_names=['Declining', 'Stable', 'Improving']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Baseline 3: Persistence Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Persistence: predict that future trajectory = current trajectory\n",
        "# This requires knowing the current trajectory for each test sample\n",
        "\n",
        "# Load full dataset to get current trajectory\n",
        "df_full = pd.read_csv('../today/trajectory_ml_ready_advanced.csv')\n",
        "df_full['Target_Label'] = df_full['Target_Label'].astype(int)\n",
        "\n",
        "# For each test sample, find its current trajectory\n",
        "# We need to match by UNITID and Year\n",
        "test_indices = y_test.index\n",
        "y_pred_persistence = []\n",
        "\n",
        "for idx in test_indices:\n",
        "    # Get the row from full dataset\n",
        "    row = df_full.iloc[idx]\n",
        "    unitid = row['UNITID']\n",
        "    year = row['Year']\n",
        "    \n",
        "    # Find the same institution in previous year\n",
        "    prev_year_data = df_full[(df_full['UNITID'] == unitid) & (df_full['Year'] == year - 1)]\n",
        "    \n",
        "    if not prev_year_data.empty:\n",
        "        # Use previous year's trajectory as prediction\n",
        "        prev_trajectory = prev_year_data.iloc[0]['Target_Label']\n",
        "        y_pred_persistence.append(prev_trajectory)\n",
        "    else:\n",
        "        # If no previous year, use majority class\n",
        "        y_pred_persistence.append(majority_class)\n",
        "\n",
        "y_pred_persistence = np.array(y_pred_persistence)\n",
        "\n",
        "accuracy_persistence = accuracy_score(y_test, y_pred_persistence)\n",
        "print(f\"Persistence Model Accuracy: {accuracy_persistence:.4f} ({accuracy_persistence*100:.2f}%)\")\n",
        "print(\"(Predicts that future trajectory = current trajectory)\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_persistence, \n",
        "                          target_names=['Declining', 'Stable', 'Improving']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Baseline 4: Simple Rule-Based Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple rule: Use key features to make predictions\n",
        "# Rules based on domain knowledge:\n",
        "# - If revenue growth is high and efficiency is good ‚Üí Improving\n",
        "# - If revenue is declining or expenses growing fast ‚Üí Declining\n",
        "# - Otherwise ‚Üí Stable\n",
        "\n",
        "def simple_rule_predict(row):\n",
        "    \"\"\"Simple rule-based prediction\"\"\"\n",
        "    # Get key features\n",
        "    revenue_growth = row.get('Revenue_Growth_1yr', 0)\n",
        "    expense_growth = row.get('Expense_Growth_1yr', 0)\n",
        "    efficiency = row.get('Efficiency_Mean_2yr', 1.0)\n",
        "    \n",
        "    # Rule 1: Improving - High revenue growth and good efficiency\n",
        "    if revenue_growth > 0.05 and efficiency > 1.0:\n",
        "        return 2  # Improving\n",
        "    \n",
        "    # Rule 2: Declining - Negative revenue growth OR expenses growing much faster\n",
        "    if revenue_growth < -0.02 or (expense_growth - revenue_growth) > 0.05:\n",
        "        return 0  # Declining\n",
        "    \n",
        "    # Rule 3: Default to Stable\n",
        "    return 1  # Stable\n",
        "\n",
        "# Apply rules to test set\n",
        "y_pred_rules = X_test.apply(simple_rule_predict, axis=1).values\n",
        "\n",
        "accuracy_rules = accuracy_score(y_test, y_pred_rules)\n",
        "print(f\"Simple Rule-Based Accuracy: {accuracy_rules:.4f} ({accuracy_rules*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_rules, \n",
        "                          target_names=['Declining', 'Stable', 'Improving']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compare All Baselines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "baseline_results = {\n",
        "    'Baseline': ['Random Guess', 'Majority Class', 'Persistence', 'Simple Rules'],\n",
        "    'Accuracy': [accuracy_random, accuracy_majority, accuracy_persistence, accuracy_rules],\n",
        "    'Predictions': [y_pred_random, y_pred_majority, y_pred_persistence, y_pred_rules]\n",
        "}\n",
        "\n",
        "baseline_df = pd.DataFrame({\n",
        "    'Baseline': baseline_results['Baseline'],\n",
        "    'Accuracy': baseline_results['Accuracy']\n",
        "})\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"BASELINE MODELS COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "print(baseline_df.to_string(index=False))\n",
        "\n",
        "# Find best baseline\n",
        "best_baseline_idx = baseline_df['Accuracy'].idxmax()\n",
        "best_baseline = baseline_df.iloc[best_baseline_idx]\n",
        "print(f\"\\n‚úÖ Best Baseline: {best_baseline['Baseline']} with {best_baseline['Accuracy']:.4f} accuracy\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(baseline_df['Baseline'], baseline_df['Accuracy'], \n",
        "               color=['#e74c3c', '#3498db', '#2ecc71', '#f39c12'])\n",
        "plt.axhline(y=0.333, color='r', linestyle='--', label='Random (33.3%)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Baseline Models Performance Comparison')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('baseline_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Chart saved as 'baseline_comparison.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Compare with ML Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved ML model to compare\n",
        "import joblib\n",
        "\n",
        "try:\n",
        "    ml_model = joblib.load('../today/models/final_trajectory_model.joblib')\n",
        "    \n",
        "    # Prepare test data for ML model (same preprocessing)\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from sklearn.compose import ColumnTransformer\n",
        "    \n",
        "    # Get predictions from ML model\n",
        "    y_pred_ml = ml_model.predict(X_test)\n",
        "    y_prob_ml = ml_model.predict_proba(X_test)\n",
        "    \n",
        "    accuracy_ml = accuracy_score(y_test, y_pred_ml)\n",
        "    \n",
        "    # Calculate ROC-AUC\n",
        "    try:\n",
        "        roc_auc_ml = roc_auc_score(y_test, y_prob_ml, multi_class='ovr')\n",
        "    except:\n",
        "        roc_auc_ml = None\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ML MODEL vs BASELINES\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    comparison = pd.DataFrame({\n",
        "        'Model': ['Random Guess', 'Majority Class', 'Persistence', 'Simple Rules', 'XGBoost (ML)'],\n",
        "        'Accuracy': [accuracy_random, accuracy_majority, accuracy_persistence, accuracy_rules, accuracy_ml]\n",
        "    })\n",
        "    \n",
        "    if roc_auc_ml:\n",
        "        comparison['ROC-AUC'] = [None, None, None, None, roc_auc_ml]\n",
        "    \n",
        "    print(comparison.to_string(index=False))\n",
        "    \n",
        "    # Calculate improvement over best baseline\n",
        "    best_baseline_acc = max(accuracy_random, accuracy_majority, accuracy_persistence, accuracy_rules)\n",
        "    improvement = accuracy_ml - best_baseline_acc\n",
        "    improvement_pct = (improvement / best_baseline_acc) * 100\n",
        "    \n",
        "    print(f\"\\nüìà ML Model Improvement:\")\n",
        "    print(f\"   Best Baseline: {best_baseline_acc:.4f}\")\n",
        "    print(f\"   ML Model: {accuracy_ml:.4f}\")\n",
        "    print(f\"   Improvement: +{improvement:.4f} ({improvement_pct:+.2f}%)\")\n",
        "    \n",
        "    if roc_auc_ml:\n",
        "        print(f\"   ROC-AUC: {roc_auc_ml:.4f}\")\n",
        "    \n",
        "    # Visualize comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    models = comparison['Model'].values\n",
        "    accuracies = comparison['Accuracy'].values\n",
        "    \n",
        "    bars = plt.bar(models, accuracies, color=['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6'])\n",
        "    plt.axhline(y=0.333, color='r', linestyle='--', alpha=0.5, label='Random (33.3%)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('ML Model vs Baseline Models')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('ml_vs_baselines.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è ML model file not found. Skipping ML comparison.\")\n",
        "    print(\"   Run this after the model has been trained and saved.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
